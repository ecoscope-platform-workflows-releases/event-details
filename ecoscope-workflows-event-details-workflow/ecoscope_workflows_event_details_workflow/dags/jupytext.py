# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Event Details
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.analysis import dataframe_count as dataframe_count
from ecoscope_workflows_core.tasks.config import (
    concat_string_vars as concat_string_vars,
)
from ecoscope_workflows_core.tasks.config import (
    default_if_string_is_empty as default_if_string_is_empty,
)
from ecoscope_workflows_core.tasks.config import (
    get_column_names_from_dataframe as get_column_names_from_dataframe,
)
from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.config import title_case_var as title_case_var
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_plot_widget_single_view as create_plot_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_single_value_widget_single_view as create_single_value_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_table_widget_single_view as create_table_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_is_empty_string as any_dependency_is_empty_string,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_is_none as any_dependency_is_none,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.skip import never as never
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import assign_value as assign_value
from ecoscope_workflows_core.tasks.transformation import (
    convert_column_values_to_numeric as convert_column_values_to_numeric,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import (
    extract_value_from_json_column as extract_value_from_json_column,
)
from ecoscope_workflows_core.tasks.transformation import fill_na as fill_na
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_core.tasks.transformation import map_values as map_values
from ecoscope_workflows_core.tasks.transformation import (
    reorder_columns as reorder_columns,
)
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_core.tasks.transformation import (
    title_case_columns_by_prefix as title_case_columns_by_prefix,
)
from ecoscope_workflows_core.tasks.transformation import transpose as transpose
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    calculate_feature_density as calculate_feature_density,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    create_meshgrid as create_meshgrid,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import summarize_df as summarize_df
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_analysis_field_from_event_details as get_analysis_field_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_analysis_field_label_from_event_details as get_analysis_field_label_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_analysis_field_unit_from_event_details as get_analysis_field_unit_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_category_field_from_event_details as get_category_field_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_category_field_label_from_event_details as get_category_field_label_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_choices_from_v2_event_type as get_choices_from_v2_event_type,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_event_type_from_event_details as get_event_type_from_event_details,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_events_from_combined_params as get_events_from_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    set_event_details_params as set_event_details_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_point_layer as create_point_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polygon_layer as create_polygon_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_pie_chart as draw_pie_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_table as draw_table
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_time_series_bar_chart as draw_time_series_bar_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.skip import (
    all_geometry_are_none as all_geometry_are_none,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification as apply_classification,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_reloc_coord_filter as apply_reloc_coord_filter,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    drop_nan_values_by_column as drop_nan_values_by_column,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    drop_null_geometry as drop_null_geometry,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    normalize_json_column as normalize_json_column,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    normalize_numeric_column as normalize_numeric_column,
)

# %% [markdown]
# ## Workflow Details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.set_task_instance_id("workflow_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Data Source

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Time Range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
    timezone=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_format="%d %b %Y %H:%M:%S", **time_range_params)
    .call()
)


# %% [markdown]
# ## Extract Timezone Selection

# %%
# parameters

get_timezone_params = dict()

# %%
# call the task


get_timezone = (
    get_timezone_from_time_range.set_task_instance_id("get_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, **get_timezone_params)
    .call()
)


# %% [markdown]
# ## Event Types

# %%
# parameters

set_event_details_combined_params = dict(
    event_type=...,
    analysis_field=...,
    analysis_field_label=...,
    analysis_field_unit=...,
    category_field=...,
    category_field_label=...,
    include_null_geometry=...,
)

# %%
# call the task


set_event_details_combined = (
    set_event_details_params.set_task_instance_id("set_event_details_combined")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        event_columns=[
            "id",
            "time",
            "event_type",
            "event_category",
            "reported_by",
            "serial_number",
            "location",
            "event_details",
            "geometry",
        ],
        raise_on_empty=False,
        include_details=True,
        include_updates=False,
        include_related_events=False,
        include_display_values=False,
        **set_event_details_combined_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

get_events_data_params = dict()

# %%
# call the task


get_events_data = (
    get_events_from_combined_params.set_task_instance_id("get_events_data")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_event_details_combined, **get_events_data_params)
    .call()
)


# %% [markdown]
# ## Convert to timezone

# %%
# parameters

convert_to_user_timezone_params = dict()

# %%
# call the task


convert_to_user_timezone = (
    convert_values_to_timezone.set_task_instance_id("convert_to_user_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=get_events_data,
        timezone=get_timezone,
        columns=["time"],
        **convert_to_user_timezone_params,
    )
    .call()
)


# %% [markdown]
# ## Extract Latitude from Events

# %%
# parameters

extract_latitude_params = dict()

# %%
# call the task


extract_latitude = (
    extract_value_from_json_column.set_task_instance_id("extract_latitude")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_to_user_timezone,
        column_name="location",
        field_name_options=["latitude"],
        output_type="str",
        output_column_name="latitude",
        **extract_latitude_params,
    )
    .call()
)


# %% [markdown]
# ## Extract Longitude from Events

# %%
# parameters

extract_longitude_params = dict()

# %%
# call the task


extract_longitude = (
    extract_value_from_json_column.set_task_instance_id("extract_longitude")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=extract_latitude,
        column_name="location",
        field_name_options=["longitude"],
        output_type="str",
        output_column_name="longitude",
        **extract_longitude_params,
    )
    .call()
)


# %% [markdown]
# ## Extract reported_by_name from Events

# %%
# parameters

extract_reported_by_params = dict()

# %%
# call the task


extract_reported_by = (
    extract_value_from_json_column.set_task_instance_id("extract_reported_by")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=extract_longitude,
        column_name="reported_by",
        field_name_options=["name"],
        output_type="str",
        output_column_name="reported_by_name",
        **extract_reported_by_params,
    )
    .call()
)


# %% [markdown]
# ## Group Data

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ## Event Location Filter

# %%
# parameters

filter_events_params = dict(
    bounding_box=...,
    filter_point_coords=...,
)

# %%
# call the task


filter_events = (
    apply_reloc_coord_filter.set_task_instance_id("filter_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=extract_reported_by,
        roi_gdf=None,
        roi_name=None,
        reset_index=True,
        **filter_events_params,
    )
    .call()
)


# %% [markdown]
# ## Normalize event details

# %%
# parameters

normalize_event_details_params = dict()

# %%
# call the task


normalize_event_details = (
    normalize_json_column.set_task_instance_id("normalize_event_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=filter_events,
        column="event_details",
        skip_if_not_exists=False,
        sort_columns=False,
        **normalize_event_details_params,
    )
    .call()
)


# %% [markdown]
# ## Add temporal index to Events

# %%
# parameters

events_add_temporal_index_params = dict()

# %%
# call the task


events_add_temporal_index = (
    add_temporal_index.set_task_instance_id("events_add_temporal_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=normalize_event_details,
        time_col="time",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **events_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

analysis_field_from_config_params = dict()

# %%
# call the task


analysis_field_from_config = (
    get_analysis_field_from_event_details.set_task_instance_id(
        "analysis_field_from_config"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        combined_params=set_event_details_combined, **analysis_field_from_config_params
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

analysis_field_params = dict()

# %%
# call the task


analysis_field = (
    title_case_var.set_task_instance_id("analysis_field")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var=analysis_field_from_config, **analysis_field_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

analysis_field_label_params = dict()

# %%
# call the task


analysis_field_label = (
    get_analysis_field_label_from_event_details.set_task_instance_id(
        "analysis_field_label"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_event_details_combined, **analysis_field_label_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

analysis_field_unit_params = dict()

# %%
# call the task


analysis_field_unit = (
    get_analysis_field_unit_from_event_details.set_task_instance_id(
        "analysis_field_unit"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_event_details_combined, **analysis_field_unit_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

category_field_from_config_params = dict()

# %%
# call the task


category_field_from_config = (
    get_category_field_from_event_details.set_task_instance_id(
        "category_field_from_config"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        combined_params=set_event_details_combined, **category_field_from_config_params
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

category_field_params = dict()

# %%
# call the task


category_field = (
    title_case_var.set_task_instance_id("category_field")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_dependency_is_none,
        ],
        unpack_depth=1,
    )
    .partial(var=category_field_from_config, **category_field_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

category_field_label_params = dict()

# %%
# call the task


category_field_label = (
    get_category_field_label_from_event_details.set_task_instance_id(
        "category_field_label"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_dependency_is_none,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_event_details_combined, **category_field_label_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

event_type_params = dict()

# %%
# call the task


event_type = (
    get_event_type_from_event_details.set_task_instance_id("event_type")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_event_details_combined, **event_type_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

add_default_category_column_params = dict()

# %%
# call the task


add_default_category_column = (
    assign_value.set_task_instance_id("add_default_category_column")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=events_add_temporal_index,
        column_name="default_category",
        value=analysis_field_unit,
        noop_if_column_exists=False,
        **add_default_category_column_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

default_category_field_params = dict()

# %%
# call the task


default_category_field = (
    default_if_string_is_empty.set_task_instance_id("default_category_field")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        value=category_field,
        default="default_category",
        **default_category_field_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

category_field_label_or_category_params = dict()

# %%
# call the task


category_field_label_or_category = (
    default_if_string_is_empty.set_task_instance_id("category_field_label_or_category")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        value=category_field_label,
        default=category_field,
        **category_field_label_or_category_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

default_category_field_label_params = dict()

# %%
# call the task


default_category_field_label = (
    default_if_string_is_empty.set_task_instance_id("default_category_field_label")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        value=category_field_label_or_category,
        default=category_field,
        **default_category_field_label_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

title_case_columns_params = dict()

# %%
# call the task


title_case_columns = (
    title_case_columns_by_prefix.set_task_instance_id("title_case_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=add_default_category_column,
        prefix="event_details__",
        **title_case_columns_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

get_category_display_names_params = dict()

# %%
# call the task


get_category_display_names = (
    get_choices_from_v2_event_type.set_task_instance_id("get_category_display_names")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        event_type=event_type,
        choice_field=category_field_from_config,
        **get_category_display_names_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

ensure_analysis_column_params = dict()

# %%
# call the task


ensure_analysis_column = (
    assign_value.set_task_instance_id("ensure_analysis_column")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=title_case_columns,
        column_name=analysis_field,
        value=None,
        noop_if_column_exists=True,
        **ensure_analysis_column_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

ensure_category_column_params = dict()

# %%
# call the task


ensure_category_column = (
    assign_value.set_task_instance_id("ensure_category_column")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=ensure_analysis_column,
        column_name=default_category_field,
        value="None",
        noop_if_column_exists=True,
        **ensure_category_column_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

map_display_names_params = dict()

# %%
# call the task


map_display_names = (
    map_values.set_task_instance_id("map_display_names")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=ensure_category_column,
        column_name=default_category_field,
        value_map=get_category_display_names,
        missing_values="preserve",
        replacement=None,
        **map_display_names_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

convert_na_values_params = dict()

# %%
# call the task


convert_na_values = (
    fill_na.set_task_instance_id("convert_na_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=map_display_names,
        value="None",
        columns=[default_category_field],
        **convert_na_values_params,
    )
    .call()
)


# %% [markdown]
# ## Rename columns for display

# %%
# parameters

rename_columns_params = dict()

# %%
# call the task


rename_columns = (
    map_columns.set_task_instance_id("rename_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=convert_na_values,
        drop_columns=["reported_by", "location", "Updates"],
        retain_columns=[],
        rename_columns={
            "serial_number": "Serial Number",
            "time": "Event Time",
            "reported_by_name": "Reported By",
            "latitude": "Latitude",
            "longitude": "Longitude",
            "event_category": "Event Category",
        },
        **rename_columns_params,
    )
    .call()
)


# %% [markdown]
# ## Reorder columns for display

# %%
# parameters

column_display_order_params = dict()

# %%
# call the task


column_display_order = (
    reorder_columns.set_task_instance_id("column_display_order")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=rename_columns,
        columns=["Serial Number", "Event Time", "Reported By", "Latitude", "Longitude"],
        **column_display_order_params,
    )
    .call()
)


# %% [markdown]
# ## Ensure Numeric Analysis Field

# %%
# parameters

ensure_numeric_params = dict()

# %%
# call the task


ensure_numeric = (
    convert_column_values_to_numeric.set_task_instance_id("ensure_numeric")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=rename_columns, columns=[analysis_field], **ensure_numeric_params)
    .call()
)


# %% [markdown]
# ## Events Colormap

# %%
# parameters

events_colormap_params = dict()

# %%
# call the task


events_colormap = (
    apply_color_map.set_task_instance_id("events_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=ensure_numeric,
        input_column_name=default_category_field,
        colormap=[
            "#312B86",
            "#08D1CC",
            "#FF3FB3",
            "#20BF55",
            "#FF9F1C",
            "#6460B0",
            "#FF7FCC",
            "#4DE3DD",
            "#6BE39A",
            "#FFC46F",
            "#1E215C",
            "#C80088",
            "#008784",
            "#08853A",
            "#C46C00",
        ],
        output_column_name="events_colormap",
        **events_colormap_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_summary_table_title_params = dict()

# %%
# call the task


set_summary_table_title = (
    set_string_var.set_task_instance_id("set_summary_table_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var=analysis_field_label, **set_summary_table_title_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

by_category_field_str_params = dict()

# %%
# call the task


by_category_field_str = (
    concat_string_vars.set_task_instance_id("by_category_field_str")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_dependency_is_empty_string,
        ],
        unpack_depth=1,
    )
    .partial(values=[" by ", category_field_label], **by_category_field_str_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

pie_chart_title_pt1_params = dict()

# %%
# call the task


pie_chart_title_pt1 = (
    concat_string_vars.set_task_instance_id("pie_chart_title_pt1")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        values=["Proportion of ", analysis_field_label], **pie_chart_title_pt1_params
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_pie_chart_title_params = dict()

# %%
# call the task


set_pie_chart_title = (
    concat_string_vars.set_task_instance_id("set_pie_chart_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        values=[pie_chart_title_pt1, by_category_field_str],
        **set_pie_chart_title_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_events_map_title_params = dict()

# %%
# call the task


set_events_map_title = (
    concat_string_vars.set_task_instance_id("set_events_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        values=[analysis_field_label, by_category_field_str, " Locations"],
        **set_events_map_title_params,
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_bar_chart_title_params = dict()

# %%
# call the task


set_bar_chart_title = (
    concat_string_vars.set_task_instance_id("set_bar_chart_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        values=[analysis_field_label, by_category_field_str, " Over Time"],
        **set_bar_chart_title_params,
    )
    .call()
)


# %% [markdown]
# ## Set Density Map Title

# %%
# parameters

set_density_map_title_params = dict()

# %%
# call the task


set_density_map_title = (
    concat_string_vars.set_task_instance_id("set_density_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(values=[analysis_field_label, " Sum"], **set_density_map_title_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_events_table_title_params = dict()

# %%
# call the task


set_events_table_title = (
    set_string_var.set_task_instance_id("set_events_table_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Events Table", **set_events_table_title_params)
    .call()
)


# %% [markdown]
# ## Split Events by Group

# %%
# parameters

split_event_groups_params = dict()

# %%
# call the task


split_event_groups = (
    split_groups.set_task_instance_id("split_event_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(df=events_colormap, groupers=groupers, **split_event_groups_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

drop_nan_values_params = dict()

# %%
# call the task


drop_nan_values = (
    drop_nan_values_by_column.set_task_instance_id("drop_nan_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name=analysis_field, **drop_nan_values_params)
    .mapvalues(argnames=["df"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Map Base Layers

# %%
# parameters

base_map_defs_params = dict(
    base_maps=...,
)

# %%
# call the task


base_map_defs = (
    set_base_maps.set_task_instance_id("base_map_defs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**base_map_defs_params)
    .call()
)


# %% [markdown]
# ## Calculate Total Events Per Group

# %%
# parameters

total_events_params = dict()

# %%
# call the task


total_events = (
    dataframe_count.set_task_instance_id("total_events")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**total_events_params)
    .mapvalues(argnames=["df"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Create Events Single Value Widget

# %%
# parameters

total_events_sv_widget_params = dict()

# %%
# call the task


total_events_sv_widget = (
    create_single_value_widget_single_view.set_task_instance_id(
        "total_events_sv_widget"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Event Count", decimal_places=1, **total_events_sv_widget_params)
    .map(argnames=["view", "data"], argvalues=total_events)
)


# %% [markdown]
# ## Merge per group Total Patrols SV widgets

# %%
# parameters

total_events_grouped_sv_widget_params = dict()

# %%
# call the task


total_events_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("total_events_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=total_events_sv_widget, **total_events_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Summarize events

# %%
# parameters

grouped_event_summary_params = dict()

# %%
# call the task


grouped_event_summary = (
    summarize_df.set_task_instance_id("grouped_event_summary")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        summary_params=[
            {"display_name": "Sum", "aggregator": "sum", "column": analysis_field},
            {"display_name": "Min", "aggregator": "min", "column": analysis_field},
            {"display_name": "Max", "aggregator": "max", "column": analysis_field},
            {
                "display_name": "Median",
                "aggregator": "median",
                "column": analysis_field,
            },
            {"display_name": "Mean", "aggregator": "mean", "column": analysis_field},
        ],
        groupby_cols=None,
        reset_index=False,
        **grouped_event_summary_params,
    )
    .mapvalues(argnames=["df"], argvalues=drop_nan_values)
)


# %% [markdown]
# ## Transpose Table

# %%
# parameters

transpose_table_params = dict()

# %%
# call the task


transpose_table = (
    transpose.set_task_instance_id("transpose_table")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(transposed_column_name="Summary Stats", **transpose_table_params)
    .mapvalues(argnames=["df"], argvalues=grouped_event_summary)
)


# %% [markdown]
# ## Rename summary column

# %%
# parameters

rename_summary_columns_params = dict()

# %%
# call the task


rename_summary_columns = (
    map_columns.set_task_instance_id("rename_summary_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={"0": "Summary Values"},
        **rename_summary_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=transpose_table)
)


# %% [markdown]
# ## Summary Table

# %%
# parameters

summary_table_params = dict()

# %%
# call the task


summary_table = (
    draw_table.set_task_instance_id("summary_table")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        columns=["Summary Stats", "Summary Values"],
        table_config={
            "enable_sorting": True,
            "enable_filtering": False,
            "enable_download": True,
            "hide_header": True,
        },
        widget_id=set_summary_table_title,
        **summary_table_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=rename_summary_columns)
)


# %% [markdown]
# ## Persist Summary Table as Text

# %%
# parameters

summary_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


summary_html_urls = (
    persist_text.set_task_instance_id("summary_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **summary_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=summary_table)
)


# %% [markdown]
# ## Create Table Widget for Summary

# %%
# parameters

summary_table_single_views_params = dict()

# %%
# call the task


summary_table_single_views = (
    create_table_widget_single_view.set_task_instance_id("summary_table_single_views")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_summary_table_title, **summary_table_single_views_params)
    .map(argnames=["view", "data"], argvalues=summary_html_urls)
)


# %% [markdown]
# ## Merge Summary Table Widget Views

# %%
# parameters

grouped_summary_table_widget_params = dict()

# %%
# call the task


grouped_summary_table_widget = (
    merge_widget_views.set_task_instance_id("grouped_summary_table_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=summary_table_single_views, **grouped_summary_table_widget_params)
    .call()
)


# %% [markdown]
# ## Draw Pie Chart for Events

# %%
# parameters

grouped_events_pie_chart_params = dict()

# %%
# call the task


grouped_events_pie_chart = (
    draw_pie_chart.set_task_instance_id("grouped_events_pie_chart")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        value_column=analysis_field,
        color_column="events_colormap",
        plot_style={"textinfo": "value"},
        label_column=default_category_field,
        layout_style=None,
        widget_id=set_pie_chart_title,
        **grouped_events_pie_chart_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=drop_nan_values)
)


# %% [markdown]
# ## Persist Pie Chart as Text

# %%
# parameters

grouped_pie_chart_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


grouped_pie_chart_html_urls = (
    persist_text.set_task_instance_id("grouped_pie_chart_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_pie_chart_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_events_pie_chart)
)


# %% [markdown]
# ## Create Plot Widget for Events

# %%
# parameters

grouped_events_pie_chart_widgets_params = dict()

# %%
# call the task


grouped_events_pie_chart_widgets = (
    create_plot_widget_single_view.set_task_instance_id(
        "grouped_events_pie_chart_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_pie_chart_title, **grouped_events_pie_chart_widgets_params)
    .map(argnames=["view", "data"], argvalues=grouped_pie_chart_html_urls)
)


# %% [markdown]
# ## Merge Pie Chart Widget Views

# %%
# parameters

grouped_events_pie_widget_merge_params = dict()

# %%
# call the task


grouped_events_pie_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_events_pie_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=grouped_events_pie_chart_widgets,
        **grouped_events_pie_widget_merge_params,
    )
    .call()
)


# %% [markdown]
# ## Normalize numeric values

# %%
# parameters

normalize_analysis_field_params = dict()

# %%
# call the task


normalize_analysis_field = (
    normalize_numeric_column.set_task_instance_id("normalize_analysis_field")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column=analysis_field,
        output_column_name="normalized_analysis_field",
        **normalize_analysis_field_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_event_groups)
)


# %% [markdown]
# ##

# %%
# parameters

drop_empty_geometry_params = dict()

# %%
# call the task


drop_empty_geometry = (
    drop_null_geometry.set_task_instance_id("drop_empty_geometry")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**drop_empty_geometry_params)
    .mapvalues(argnames=["gdf"], argvalues=normalize_analysis_field)
)


# %% [markdown]
# ## Create map layer from grouped Events

# %%
# parameters

grouped_events_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


grouped_events_map_layer = (
    create_point_layer.set_task_instance_id("grouped_events_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "fill_color_column": "events_colormap",
            "get_radius": "normalized_analysis_field",
            "stroked": True,
            "get_line_color": "#FFFFFF",
            "radius_scale": 5,
        },
        legend={
            "label_column": default_category_field,
            "color_column": "events_colormap",
        },
        tooltip_columns=["Serial Number", "Event Time", "Reported By", analysis_field],
        **grouped_events_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=drop_empty_geometry)
)


# %% [markdown]
# ## Draw Ecomap from grouped Events

# %%
# parameters

grouped_events_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


grouped_events_ecomap = (
    draw_ecomap.set_task_instance_id("grouped_events_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        title=None,
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": default_category_field_label,
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        max_zoom=20,
        widget_id=set_events_map_title,
        **grouped_events_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=grouped_events_map_layer)
)


# %% [markdown]
# ## Persist grouped Events Ecomap as Text

# %%
# parameters

grouped_events_ecomap_html_url_params = dict(
    filename=...,
)

# %%
# call the task


grouped_events_ecomap_html_url = (
    persist_text.set_task_instance_id("grouped_events_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_events_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_events_ecomap)
)


# %% [markdown]
# ## Create grouped Events Map Widget

# %%
# parameters

grouped_events_map_widget_params = dict()

# %%
# call the task


grouped_events_map_widget = (
    create_map_widget_single_view.set_task_instance_id("grouped_events_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_events_map_title, **grouped_events_map_widget_params)
    .map(argnames=["view", "data"], argvalues=grouped_events_ecomap_html_url)
)


# %% [markdown]
# ## Merge Events Map Widget Views

# %%
# parameters

grouped_events_map_widget_merge_params = dict()

# %%
# call the task


grouped_events_map_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_events_map_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=grouped_events_map_widget, **grouped_events_map_widget_merge_params
    )
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

events_bar_chart_params = dict(
    time_interval=...,
)

# %%
# call the task


events_bar_chart = (
    draw_time_series_bar_chart.set_task_instance_id("events_bar_chart")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        x_axis="Event Time",
        y_axis=analysis_field,
        category=default_category_field,
        agg_function="sum",
        color_column="events_colormap",
        plot_style={"xperiodalignment": "middle"},
        layout_style=None,
        widget_id=set_bar_chart_title,
        **events_bar_chart_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=drop_nan_values)
)


# %% [markdown]
# ## Persist Bar Chart as Text

# %%
# parameters

events_bar_chart_html_url_params = dict(
    filename=...,
)

# %%
# call the task


events_bar_chart_html_url = (
    persist_text.set_task_instance_id("events_bar_chart_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **events_bar_chart_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=events_bar_chart)
)


# %% [markdown]
# ## Create Bar Plot Widget for Events

# %%
# parameters

events_bar_chart_widget_params = dict()

# %%
# call the task


events_bar_chart_widget = (
    create_plot_widget_single_view.set_task_instance_id("events_bar_chart_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_bar_chart_title, **events_bar_chart_widget_params)
    .map(argnames=["view", "data"], argvalues=events_bar_chart_html_url)
)


# %% [markdown]
# ## Merge Bar Plot Widget Views

# %%
# parameters

grouped_bar_plot_widget_merge_params = dict()

# %%
# call the task


grouped_bar_plot_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_bar_plot_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=events_bar_chart_widget, **grouped_bar_plot_widget_merge_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

events_meshgrid_params = dict(
    auto_scale_or_custom_cell_size=...,
    crs=...,
)

# %%
# call the task


events_meshgrid = (
    create_meshgrid.set_task_instance_id("events_meshgrid")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        aoi=events_add_temporal_index, intersecting_only=False, **events_meshgrid_params
    )
    .call()
)


# %% [markdown]
# ## Grouped Events Feature Density

# %%
# parameters

grouped_events_feature_density_params = dict()

# %%
# call the task


grouped_events_feature_density = (
    calculate_feature_density.set_task_instance_id("grouped_events_feature_density")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        meshgrid=events_meshgrid,
        geometry_type="point",
        sum_column=analysis_field,
        **grouped_events_feature_density_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Drop nan percentiles for map display

# %%
# parameters

drop_nan_percentiles_params = dict()

# %%
# call the task


drop_nan_percentiles = (
    drop_nan_values_by_column.set_task_instance_id("drop_nan_percentiles")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="density", **drop_nan_percentiles_params)
    .mapvalues(argnames=["df"], argvalues=grouped_events_feature_density)
)


# %% [markdown]
# ## Sort Density By Classification

# %%
# parameters

sort_grouped_density_values_params = dict()

# %%
# call the task


sort_grouped_density_values = (
    sort_values.set_task_instance_id("sort_grouped_density_values")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="density",
        ascending=True,
        na_position="last",
        **sort_grouped_density_values_params,
    )
    .mapvalues(argnames=["df"], argvalues=drop_nan_percentiles)
)


# %% [markdown]
# ## Classify Density Values

# %%
# parameters

classify_fd_params = dict()

# %%
# call the task


classify_fd = (
    apply_classification.set_task_instance_id("classify_fd")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="density",
        output_column_name="density_bins",
        classification_options={"scheme": "equal_interval", "k": 9},
        label_options={"label_ranges": True, "label_decimals": 0},
        **classify_fd_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_grouped_density_values)
)


# %% [markdown]
# ## Grouped Feature Density Colormap

# %%
# parameters

grouped_fd_colormap_params = dict()

# %%
# call the task


grouped_fd_colormap = (
    apply_color_map.set_task_instance_id("grouped_fd_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="density_bins",
        colormap=[
            "#5C4FE7",
            "#269CD5",
            "#00D0C8",
            "#81D670",
            "#FFD000",
            "#F9BB12",
            "#FF9600",
            "#FA7306",
            "#F23B0E",
        ],
        output_column_name="density_colormap",
        **grouped_fd_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=classify_fd)
)


# %% [markdown]
# ## Rename columns for map tooltip display

# %%
# parameters

fd_rename_columns_params = dict()

# %%
# call the task


fd_rename_columns = (
    map_columns.set_task_instance_id("fd_rename_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={"density": "Density"},
        **fd_rename_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=grouped_fd_colormap)
)


# %% [markdown]
# ## Create map layer from Feature Density

# %%
# parameters

grouped_fd_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


grouped_fd_map_layer = (
    create_polygon_layer.set_task_instance_id("grouped_fd_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "fill_color_column": "density_colormap",
            "get_line_width": 0,
            "opacity": 0.4,
        },
        legend={"label_column": "density_bins", "color_column": "density_colormap"},
        tooltip_columns=["Density"],
        **grouped_fd_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=fd_rename_columns)
)


# %% [markdown]
# ## Draw Ecomap from Feature Density

# %%
# parameters

grouped_fd_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


grouped_fd_ecomap = (
    draw_ecomap.set_task_instance_id("grouped_fd_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        title=None,
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": analysis_field_unit,
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        max_zoom=20,
        widget_id=set_density_map_title,
        **grouped_fd_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=grouped_fd_map_layer)
)


# %% [markdown]
# ## Persist Feature Density Ecomap as Text

# %%
# parameters

grouped_fd_ecomap_html_url_params = dict(
    filename=...,
)

# %%
# call the task


grouped_fd_ecomap_html_url = (
    persist_text.set_task_instance_id("grouped_fd_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **grouped_fd_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=grouped_fd_ecomap)
)


# %% [markdown]
# ## Create Feature Density Map Widget

# %%
# parameters

grouped_fd_map_widget_params = dict()

# %%
# call the task


grouped_fd_map_widget = (
    create_map_widget_single_view.set_task_instance_id("grouped_fd_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_density_map_title, **grouped_fd_map_widget_params)
    .map(argnames=["view", "data"], argvalues=grouped_fd_ecomap_html_url)
)


# %% [markdown]
# ## Merge Feature Density Widget Views

# %%
# parameters

grouped_fd_map_widget_merge_params = dict()

# %%
# call the task


grouped_fd_map_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_fd_map_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=grouped_fd_map_widget, **grouped_fd_map_widget_merge_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

events_table_columns_params = dict()

# %%
# call the task


events_table_columns = (
    get_column_names_from_dataframe.set_task_instance_id("events_table_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=column_display_order,
        exclude_column_names=[
            "id",
            "geometry",
            "events_colormap",
            "event_type",
            "default_category",
            "Event Category",
        ],
        **events_table_columns_params,
    )
    .call()
)


# %% [markdown]
# ## Events Table

# %%
# parameters

events_table_params = dict()

# %%
# call the task


events_table = (
    draw_table.set_task_instance_id("events_table")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        columns=events_table_columns,
        table_config={
            "enable_sorting": True,
            "enable_filtering": False,
            "enable_download": True,
            "hide_header": False,
        },
        widget_id=set_events_table_title,
        **events_table_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=split_event_groups)
)


# %% [markdown]
# ## Persist Events Table as Text

# %%
# parameters

table_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


table_html_urls = (
    persist_text.set_task_instance_id("table_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **table_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=events_table)
)


# %% [markdown]
# ## Create Table Widgets for Events

# %%
# parameters

events_table_single_views_params = dict()

# %%
# call the task


events_table_single_views = (
    create_table_widget_single_view.set_task_instance_id("events_table_single_views")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_events_table_title, **events_table_single_views_params)
    .map(argnames=["view", "data"], argvalues=table_html_urls)
)


# %% [markdown]
# ## Merge Table Widget Views

# %%
# parameters

grouped_table_widget_params = dict()

# %%
# call the task


grouped_table_widget = (
    merge_widget_views.set_task_instance_id("grouped_table_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=events_table_single_views, **grouped_table_widget_params)
    .call()
)


# %% [markdown]
# ## Create Dashboard with Map Widgets

# %%
# parameters

events_dashboard_params = dict(
    warning=...,
)

# %%
# call the task


events_dashboard = (
    gather_dashboard.set_task_instance_id("events_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=workflow_details,
        widgets=[
            total_events_grouped_sv_widget,
            grouped_summary_table_widget,
            grouped_events_pie_widget_merge,
            grouped_events_map_widget_merge,
            grouped_bar_plot_widget_merge,
            grouped_fd_map_widget_merge,
            grouped_table_widget,
        ],
        groupers=groupers,
        time_range=time_range,
        **events_dashboard_params,
    )
    .call()
)
